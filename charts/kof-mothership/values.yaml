global:
  # -- Name of the label identifying where the time series data points come from.
  clusterLabel: cluster
  # -- Value of this label.
  clusterName: mothership

  # -- Name of the storage class used by Grafana,
  # `vmstorage` (long-term storage of raw time series data),
  # and `vmselect` (cache of query results).
  # Keep it unset or empty to leverage the advantages of
  # [default storage class](https://kubernetes.io/docs/concepts/storage/storage-classes/#default-storageclass).
  storageClass: ""

  # -- Length of the auto-generated usernames for Grafana and VictoriaMetrics.
  random_username_length: 8

  # -- Length of the auto-generated passwords for Grafana and VictoriaMetrics.
  random_password_length: 12

cert-manager:
  # -- Whether cert-manager is present in the cluster
  enabled: true
  cluster-issuer:
    # -- Whether to create a default clusterissuer
    create: false
    # -- Default clusterissuer provider
    provider: letsencrypt
  # -- If we use letsencrypt (or similar) which email to use
  email: mail@example.net

# -- Config of `ServiceTemplate` to use `cert-manager` in `MultiClusterService`.
cert-manager-service-template:
  helm:
    repository:
      name: cert-manager
      url: https://charts.jetstack.io
    charts:
      - name: cert-manager
        version: 1.16.4
  namespace: kcm-system

# -- Config of `ServiceTemplate` to use `ingress-nginx` in `MultiClusterService`.
ingress-nginx-service-template:
  helm:
    repository:
      name: ingress-nginx
      url: https://kubernetes.github.io/ingress-nginx
    charts:
      - name: ingress-nginx
        version: 4.12.1
  namespace: kcm-system

kcm:
  # -- K8s namespace created on installation of k0rdent/kcm.
  namespace: kcm-system

  # -- Installs `ServiceTemplates` to use charts like `kof-storage` in `MultiClusterService`.
  installTemplates: false

  serviceMonitor:
    # -- Enables the "KCM Controller Manager" Grafana dashboard.
    enabled: true

  kof:
    # -- Repo of `kof-*` helm charts.
    repo:
      name: kof
      spec:
        type: oci
        url: oci://ghcr.io/k0rdent/kof/charts

    # -- Names of secrets auto-distributed to clusters with matching labels.
    clusterProfiles:
      kof-storage-secrets:
        matchLabels:
          k0rdent.mirantis.com/kof-storage-secrets: "true"
        create_secrets: true
        secrets:
          - storage-vmuser-credentials

    operator:
      enabled: true
      replicaCount: 1

      rbac:
        # -- Creates the `kof-mothership-kof-operator` cluster role
        # and binds it to the service account of operator.
        create: true

      # -- Image of the kof operator.
      image:
        repository: ghcr.io/k0rdent/kof/kof-operator-controller
        pullPolicy: IfNotPresent

      resources:
        # -- Minimum resources required for operator.
        requests:
          cpu: 100m
          memory: 128Mi

        # -- Maximum resources available for operator.
        limits:
          cpu: 100m
          memory: 128Mi

      serviceAccount:
        # -- Creates a service account for operator.
        create: true

        # -- Annotations for the service account of operator.
        annotations: {}

        # -- Name for the service account of operator.
        # If not set, it is generated as `kof-mothership-kof-operator`.
        name:

victoriametrics:
  # -- Enables VictoriaMetrics.
  enabled: true

  vmcluster:
    # -- Enables high-available and fault-tolerant version of VictoriaMetrics database.
    enabled: true

    # -- The number of replicas for each metric.
    replicationFactor: 1

    # -- The number of replicas for components of cluster.
    replicaCount: 1

    # -- Days to retain the data.
    retentionPeriod: "1"

    vmselect:
      storage:
        # -- Query results cache size.
        size: 2Gi

    vmstorage:
      storage:
        # -- Long-term storage size of raw time series data.
        size: 10Gi

    vminsert:
      labels:
        # -- Label to enable mtls
        k0rdent.mirantis.com/istio-mtls-enabled: "true"

  vmalert:
    # -- Enables VMAlertManager only, as VMAlert is replaced with promxy in kof-mothership.
    enabled: true

    vmalertmanager:
      # -- `configRawYaml` of [VMAlertmanagerSpec](https://docs.victoriametrics.com/operator/api/#vmalertmanagerspec).
      # Check examples [here](https://github.com/k0rdent/kof/blob/main/docs/alerts.md).
      config: ""

grafana:
  # -- Enables Grafana.
  enabled: true

  ingress:
    # -- Enables an ingress to access Grafana without port-forwarding.
    enabled: false

    # -- Domain name Grafana will be available at.
    host: grafana.example.net

  # -- Old option to add `GrafanaDatasource`-s.
  logSources: []

  security:
    # -- Name of secret for Grafana username/password.
    credentials_secret_name: grafana-admin-credentials

    # -- Enables auto-creation of Grafana username/password.
    create_secret: true

  pvc:
    resources:
      requests:
        # -- Size of storage for Grafana.
        storage: 200Mi

  # -- Version of Grafana to use.
  version: "10.4.7"

  dashboard:
    datasource:
      # -- Regex pattern to filter datasources.
      regex: "/promxy/"

      # -- Values of current datasource
      current:
        text: promxy
        value: promxy

    # -- Values of filters to apply.
    filters:
      clusterName: mothership

    # -- Enables istio dashboards
    istio_dashboard_enabled: true

# -- [Docs](https://github.com/VictoriaMetrics/helm-charts/tree/master/charts/victoria-metrics-operator#parameters)
victoria-metrics-operator:
  enabled: true
  operator:
    disable_prometheus_converter: true
  crds:
    plain: true
    cleanup:
      enabled: true

# -- [Docs](https://github.com/Jont828/cluster-api-visualizer/tree/main/helm#configurable-values)
cluster-api-visualizer:
  enabled: true

# -- [Docs](https://projectsveltos.github.io/dashboard-helm-chart/#values)
sveltos-dashboard:
  enabled: true

sveltos:
  # -- Creates `ServiceMonitor`-s for Sveltos `sc-manager` and `addon-controller`.
  serviceMonitors: true

  # -- Adds Sveltos dashboard to Grafana.
  grafanaDashboard: true

promxy:
  # -- Enables `kof-mothership-promxy` deployment.
  enabled: true

  # -- Number of replicated promxy pods.
  replicaCount: 1

  # -- Promxy image to use.
  image:
    repository: quay.io/jacksontj/promxy
    tag: "latest"
    pullPolicy: IfNotPresent

  serviceAccount:
    # -- Creates a service account for promxy.
    create: true

    # -- Annotations for the service account of promxy.
    annotations: {}

    # -- Name for the service account of promxy.
    # If not set, it is generated as `kof-mothership-promxy`.
    name:

  # -- Config of `kof-mothership-promxy`
  # [Service](https://kubernetes.io/docs/concepts/services-networking/service/).
  service:
    enabled: true
    type: ClusterIP
    servicePort: 8082
    annotations: {}
    extraLabels: {}
    clusterIP: ""
    externalIPs: []
    loadBalancerIP: ""
    loadBalancerSourceRanges: []

  # -- Config of `kof-mothership-promxy`
  # [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/).
  ingress:
    enabled: false
    ingressClassName: nginx
    annotations: {}
    extraLabels: {}
    path: /
    pathType: Prefix
    hosts:
      - example.com
    tls: []

  resources:
    # -- Minimum resources required for the `promxy` container
    # in the pods of `kof-mothership-promxy` deployment.
    requests:
      cpu: 100m
      memory: 128Mi

    # -- Maximum resources available for the `promxy` container
    # in the pods of `kof-mothership-promxy` deployment.
    limits:
      cpu: 100m
      memory: 128Mi

  # -- Extra command line arguments passed as `--key=value` to the `/bin/promxy`.
  extraArgs:
    log-level: "info"

  configmapReload:
    resources:
      # -- Minimum resources required for the `promxy-server-configmap-reload` container
      # in the pods of `kof-mothership-promxy` deployment.
      requests:
        cpu: 0.02
        memory: 20Mi

      # -- Maximum resources available for the `promxy-server-configmap-reload` container
      # in the pods of `kof-mothership-promxy` deployment.
      limits:
        cpu: 0.02
        memory: 20Mi

# See ./templates/prometheus/_README.md
# @ignored
kube-state-metrics: {}
# @ignored
kubeApiServer: {}
# @ignored
kubeControllerManager: {}
# @ignored
kubeEtcd: {}
# @ignored
kubelet: {}
# @ignored
kubeProxy: {}
# @ignored
kubeScheduler: {}
# @ignored
prometheusOperator:
  kubeletService: {}
# @ignored
windowsMonitoring: {}

## custom Rules to override "for" and "severity" in defaultRules
##
# @ignored
customRules: {}
  # AlertmanagerFailedReload:
  #   for: 3m
  # AlertmanagerMembersInconsistent:
  #   for: 5m
  #   severity: "warning"

## Create default rules for monitoring the cluster
##
# @ignored
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    configReloaders: true
    general: true
    k8sContainerCpuUsageSecondsTotal: true
    k8sContainerMemoryCache: true
    k8sContainerMemoryRss: true
    k8sContainerMemorySwap: true
    k8sContainerResource: true
    k8sContainerMemoryWorkingSetBytes: true
    k8sPodOwner: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubeControllerManager: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeSchedulerAlerting: true
    kubeSchedulerRecording: true
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
    windows: true

  ## Reduce app namespace alert scope
  appNamespacesTarget: ".*"

  ## Set keep_firing_for for all alerts
  keepFiringFor: ""

  ## Labels for default rules
  labels: {}
  ## Annotations for default rules
  annotations: {}

  ## Additional labels for PrometheusRule alerts
  additionalRuleLabels: {}

  ## Additional annotations for PrometheusRule alerts
  additionalRuleAnnotations: {}

  ## Additional labels for specific PrometheusRule alert groups
  additionalRuleGroupLabels:
    alertmanager: {}
    etcd: {}
    configReloaders: {}
    general: {}
    k8sContainerCpuUsageSecondsTotal: {}
    k8sContainerMemoryCache: {}
    k8sContainerMemoryRss: {}
    k8sContainerMemorySwap: {}
    k8sContainerResource: {}
    k8sPodOwner: {}
    kubeApiserverAvailability: {}
    kubeApiserverBurnrate: {}
    kubeApiserverHistogram: {}
    kubeApiserverSlos: {}
    kubeControllerManager: {}
    kubelet: {}
    kubeProxy: {}
    kubePrometheusGeneral: {}
    kubePrometheusNodeRecording: {}
    kubernetesApps: {}
    kubernetesResources: {}
    kubernetesStorage: {}
    kubernetesSystem: {}
    kubeSchedulerAlerting: {}
    kubeSchedulerRecording: {}
    kubeStateMetrics: {}
    network: {}
    node: {}
    nodeExporterAlerting: {}
    nodeExporterRecording: {}
    prometheus: {}
    prometheusOperator: {}

  ## Additional annotations for specific PrometheusRule alerts groups
  additionalRuleGroupAnnotations:
    alertmanager: {}
    etcd: {}
    configReloaders: {}
    general: {}
    k8sContainerCpuUsageSecondsTotal: {}
    k8sContainerMemoryCache: {}
    k8sContainerMemoryRss: {}
    k8sContainerMemorySwap: {}
    k8sContainerResource: {}
    k8sPodOwner: {}
    kubeApiserverAvailability: {}
    kubeApiserverBurnrate: {}
    kubeApiserverHistogram: {}
    kubeApiserverSlos: {}
    kubeControllerManager: {}
    kubelet: {}
    kubeProxy: {}
    kubePrometheusGeneral: {}
    kubePrometheusNodeRecording: {}
    kubernetesApps: {}
    kubernetesResources: {}
    kubernetesStorage: {}
    kubernetesSystem: {}
    kubeSchedulerAlerting: {}
    kubeSchedulerRecording: {}
    kubeStateMetrics: {}
    network: {}
    node: {}
    nodeExporterAlerting: {}
    nodeExporterRecording: {}
    prometheus: {}
    prometheusOperator: {}

  additionalAggregationLabels: []

  ## Prefix for runbook URLs. Use this to override the first part of the runbookURLs that is common to all rules.
  runbookUrl: "https://runbooks.prometheus-operator.dev/runbooks"

  node:
    fsSelector: 'fstype!=""'
    # fsSelector: 'fstype=~"ext[234]|btrfs|xfs|zfs"'

  ## Disabled PrometheusRule alerts
  disabled: {}
  # KubeAPIDown: true
  # NodeRAIDDegraded: true

# -- Cluster-specific patch of Prometheus alerting rules,
# e.g. `cluster1.alertgroup1.alert1.expr` overriding the threshold `> ( 25 / 100 )`
# and adding `{cluster="cluster1"}` filter, or just adding whole new rules
clusterAlertRules: {}
  # cluster1:
  #   kubernetes-resources:
  #     CPUThrottlingHigh:
  #       expr: |-
  #         sum(increase(container_cpu_cfs_throttled_periods_total{cluster="cluster1", container!="", job="kubelet", metrics_path="/metrics/cadvisor", }[5m])) without (id, metrics_path, name, image, endpoint, job, node)
  #           / on (cluster, namespace, pod, container, instance) group_left
  #         sum(increase(container_cpu_cfs_periods_total{cluster="cluster1", job="kubelet", metrics_path="/metrics/cadvisor", }[5m])) without (id, metrics_path, name, image, endpoint, job, node)
  #           > ( 42 / 100 )

# -- Patch of default Prometheus alerting rules,
# e.g. `alertgroup1.alert1` overriding `for` field and adding
# `{cluster!~"^cluster1$|^cluster10$"}` for rules overridden in `clusterRulesPatch`,
# or just adding whole new rules
defaultAlertRules: {}
  # kubernetes-resources:
  #   CPUThrottlingHigh:
  #     for: 10m
  #     expr: |-
  #       sum(increase(container_cpu_cfs_throttled_periods_total{cluster!~"^cluster1$|^cluster10$", container!="", job="kubelet", metrics_path="/metrics/cadvisor", }[5m])) without (id, metrics_path, name, image, endpoint, job, node)
  #         / on (cluster, namespace, pod, container, instance) group_left
  #       sum(increase(container_cpu_cfs_periods_total{cluster!~"^cluster1$|^cluster10$", job="kubelet", metrics_path="/metrics/cadvisor", }[5m])) without (id, metrics_path, name, image, endpoint, job, node)
  #         > ( 25 / 100 )

# -- Cluster-specific patch of Prometheus recording rules,
# e.g. `regionalCluster1.recordGroup1` overriding whole group of rules
# (because `record` is not unique), or adding new groups
clusterRecordRules: {}
  # regional1:
  #   kube-prometheus-general.rules:
  #     - expr: count without(instance, pod, node) (up == 1)
  #       record: count:up1
  #     - expr: count without(instance, pod, node) (up == 0)
  #       record: count:up0
  #     - expr: count without(instance, pod, node) (up{cluster="child2"} >= 0)
  #       record: count:child2_up_or_down

# -- Patch of default Prometheus recording rules,
# e.g. `recordgroup1` overriding whole group of rules (`record` is not unique),
# or adding new groups
defaultRecordRules: {}
  # kube-prometheus-general.rules:
  #   - expr: count without(instance, pod, node) (up == 1)
  #     record: count:up1
  #   - expr: count without(instance, pod, node) (up == 0)
  #     record: count:up0
  #   - expr: count without(instance, pod, node) (up <= 1)
  #     record: count:up_or_down
  # kube-prometheus-general-default-test.rules:
  #   - expr: count without(instance, pod, node) (up >= 0)
  #     record: count:up_or_down
